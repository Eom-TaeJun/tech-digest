"""
Daily Tech Digest - Step 1: Perplexity ìˆ˜ì§‘
- sonar-pro ëª¨ë¸ë¡œ AI ì»¤ë®¤ë‹ˆí‹° ì‹¤ì‚¬ìš© í›„ê¸° ìˆ˜ì§‘
- ê²°ê³¼: raw/{date}.json + digest/{date}.md
"""

import os
import json
import requests
from datetime import datetime, timezone, timedelta

API_KEY = os.environ["PERPLEXITY_API_KEY"]
BASE_URL = "https://api.perplexity.ai/chat/completions"
MODEL = "sonar-pro"

KST = timezone(timedelta(hours=9))
TODAY = datetime.now(KST).strftime("%Y-%m-%d")

SYSTEM_PROMPT = """You are a researcher collecting real user opinions and experiences from developer communities.

Focus ONLY on:
- Reddit posts/comments (r/LocalLLaMA, r/programming, r/MachineLearning, r/ClaudeAI, r/cursor, r/OpenAI, r/GoogleGemini, r/singularity, r/artificial)
- Hacker News discussions and Show HN posts
- Twitter/X threads from actual developers
- GitHub Issues, Discussions, and trending repositories

Exclude:
- Official press releases and marketing copy
- Paywalled content

Include:
- Community reactions and first impressions of new model/tool releases
- Real-world usage comparisons between models (specific tasks, not benchmark scores)
- Honest frustrations, unexpected discoveries, and workflow changes

For each topic, find what real users are saying: what's working, what's frustrating, what surprised them, and why they switched.
Format your answer in clear sections with source citations."""

QUERIES = {
    "ai_workflow_change": [
        {
            "id": "workflow_agentic",
            "title": "ì—ì´ì „íŠ¸ ê¸°ë°˜ ê°œë°œ - ì‹¤ì œ íŒ€ ì‚¬ìš© ê²½í—˜",
            "query": "How are real developers and teams actually using AI agents to build software in 2025-2026? What changed in their daily workflow? Focus on Reddit and Hacker News discussions with honest experiences, not marketing.",
        },
        {
            "id": "workflow_vibecheck",
            "title": "ë°”ì´ë¸Œ ì½”ë”© / AI ì£¼ë„ ê°œë°œ - ì†”ì§í•œ í›„ê¸°",
            "query": "Real developer experiences with 'vibe coding' or AI-driven development in 2026. What actually works, what fails, and how teams restructured around AI coding tools. Focus on Reddit r/LocalLLaMA, r/programming, Hacker News.",
        },
        {
            "id": "workflow_team_structure",
            "title": "AIë¡œ ì¸í•œ íŒ€ êµ¬ì¡° ë³€í™”",
            "query": "How has AI changed software team structure and roles in 2025-2026? Are companies replacing junior developers? Real experiences from engineers on Reddit, Hacker News, or Twitter about job market and team dynamics.",
        },
    ],
    "new_tools": [
        {
            "id": "tools_cursor_vs_claude",
            "title": "Cursor vs Claude Code - ì‹¤ì œ ì „í™˜ ì´ìœ ",
            "query": "Why are developers switching from Cursor to Claude Code in 2026? Real user comparisons, honest pros and cons from Reddit, Hacker News, and Twitter. What made people switch and what do they miss?",
        },
        {
            "id": "tools_landscape",
            "title": "AI ì½”ë”© íˆ´ ì „ì²´ ì§€í˜• - ì»¤ë®¤ë‹ˆí‹° í‰ê°€",
            "query": "What AI coding tools are developers actually recommending in 2026? Compare Claude Code, Cursor, Windsurf, Cline, Aider based on real Reddit and Hacker News community votes and honest reviews. What are the hidden pros and cons?",
        },
        {
            "id": "tools_new_rising",
            "title": "ìƒˆë¡­ê²Œ ì£¼ëª©ë°›ëŠ” AI ê°œë°œ íˆ´",
            "query": "What new AI development tools or frameworks gained the most positive community reception in the past week? Focus on GitHub trending repos with high stars, Reddit posts with high upvotes, or Hacker News Show HN with top comments. Real user reactions only.",
        },
    ],
    "model_reactions": [
        {
            "id": "model_new_release",
            "title": "ì‹ ê·œ ëª¨ë¸/API ë¦´ë¦¬ì¦ˆ â€” ì»¤ë®¤ë‹ˆí‹° ì¦‰ê° ë°˜ì‘",
            "query": "What new AI models, APIs, or major updates were released or announced in the past 48 hours? What is the immediate community reaction on Reddit (r/LocalLLaMA, r/OpenAI, r/ClaudeAI, r/GoogleGemini, r/singularity), Hacker News, and Twitter? Capture first impressions, surprises, and disappointments â€” real user reactions only, not press releases.",
        },
        {
            "id": "model_real_perf",
            "title": "ëª¨ë¸ë³„ ì‹¤ì‚¬ìš© ì„±ëŠ¥ â€” ê°œë°œì ì§ì ‘ ë¹„êµ",
            "query": "What are developers saying about real-world differences between current AI models (Claude, GPT-4o, Gemini, Llama, Mistral, DeepSeek, etc.) this week? Focus on practical comparisons people share on Reddit r/LocalLLaMA, r/ClaudeAI, Hacker News â€” specific tasks where one model clearly beats another, not benchmark scores but actual 'I tried X and it did better/worse at Y than Z' experiences.",
        },
    ],
    "token_cost": [
        {
            "id": "token_reduction_tips",
            "title": "í† í° ì ˆì•½ â€” ì‹¤ì œ ê°œë°œì íŒê³¼ ê²½í—˜",
            "query": "What are developers actually doing to reduce LLM token usage and API costs in 2026? Real tips and experiences from Reddit (r/ClaudeAI, r/LocalLLaMA, r/MachineLearning), Hacker News, Twitter. Focus on practical tricks: prompt caching, CLAUDE.md optimization, context management, model routing. What surprised people? What actually worked vs. what didn't?",
        },
        {
            "id": "token_context_management",
            "title": "ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê´€ë¦¬ â€” ì»¤ë®¤ë‹ˆí‹° ì‹¤ì „ íŒ¨í„´",
            "query": "How are developers managing context window limits and preventing token cost blowups in AI agent systems in 2026? Real discussions from Reddit and Hacker News about sliding windows, session summarization, AGENTS.md/CLAUDE.md sizing, and prompt compression tools like LLMLingua. What are the hidden gotchas people discovered?",
        },
    ],
}


def call_perplexity(query: dict) -> dict:
    payload = {
        "model": MODEL,
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": query["query"]},
        ],
        "search_recency_filter": "day",
        "return_citations": True,
    }
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json",
    }

    print(f"  Querying: [{query['id']}] {query['title']}")
    resp = requests.post(BASE_URL, headers=headers, json=payload, timeout=60)
    resp.raise_for_status()
    data = resp.json()

    return {
        "id": query["id"],
        "title": query["title"],
        "query": query["query"],
        "answer": data["choices"][0]["message"]["content"],
        "citations": data.get("citations", []),
        "model": data.get("model", MODEL),
        "usage": data.get("usage", {}),
    }


def build_markdown(results: dict) -> str:
    lines = [
        f"# AI Tech Digest â€” {TODAY}",
        "",
        "> **ìˆ˜ì§‘ ë°©ì‹**: Perplexity sonar-pro / ì‹¤ì œ ì»¤ë®¤ë‹ˆí‹° í›„ê¸° ì¤‘ì‹¬ (Reddit, HN, Twitter)",
        "> **ì£¼ì˜**: ì´ íŒŒì¼ì€ ì›ë³¸ ìˆ˜ì§‘ ê²°ê³¼ì…ë‹ˆë‹¤. Claude ì¬ìš”ì•½ë³¸ì€ ë³„ë„ íŒŒì¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.",
        "",
        "---",
        "",
    ]

    section_meta = {
        "ai_workflow_change": ("## 1. AIë¡œ ì¸í•œ êµ¬ì¡°/ë°©ì‹ ë³€í™”", "ğŸ”„"),
        "new_tools": ("## 2. ìƒˆë¡œìš´ AI íˆ´ â€” ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘", "ğŸ› ï¸"),
        "model_reactions": ("## 3. ì‹ ê·œ ëª¨ë¸/API â€” ì‹¤ì‚¬ìš© ë°˜ì‘", "ğŸ¤–"),
        "token_cost": ("## 4. í† í° ë¹„ìš© & ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬", "ğŸ’°"),
    }

    for section_key, queries in QUERIES.items():
        heading, emoji = section_meta[section_key]
        lines.append(f"{heading}")
        lines.append("")

        for q in queries:
            qid = q["id"]
            if qid not in results:
                continue

            r = results[qid]
            lines.append(f"### {emoji} {r['title']}")
            lines.append("")
            lines.append(r["answer"])
            lines.append("")

            if r.get("citations"):
                lines.append("**Sources:**")
                for i, url in enumerate(r["citations"], 1):
                    lines.append(f"{i}. {url}")
                lines.append("")

            lines.append("---")
            lines.append("")

    lines.append(f"*Generated at {datetime.now(KST).strftime('%Y-%m-%d %H:%M KST')} by [tech-digest](https://github.com)*")
    return "\n".join(lines)


def main():
    print(f"[{TODAY}] Daily Tech Digest ìˆ˜ì§‘ ì‹œì‘ (model: {MODEL})")

    raw_results = {}
    all_queries = [q for qs in QUERIES.values() for q in qs]

    for q in all_queries:
        try:
            result = call_perplexity(q)
            raw_results[q["id"]] = result
            print(f"    âœ“ {q['id']} ({result['usage'].get('total_tokens', '?')} tokens)")
        except Exception as e:
            print(f"    âœ— {q['id']}: {e}")

    # Step 1: raw JSON ì €ì¥
    raw_path = f"raw/{TODAY}.json"
    os.makedirs("raw", exist_ok=True)
    with open(raw_path, "w", encoding="utf-8") as f:
        json.dump(
            {"date": TODAY, "model": MODEL, "results": raw_results},
            f,
            ensure_ascii=False,
            indent=2,
        )
    print(f"  â†’ raw ì €ì¥: {raw_path}")

    # Step 2: ë§ˆí¬ë‹¤ìš´ ë‹¤ì´ì œìŠ¤íŠ¸ ìƒì„±
    md_path = f"digest/{TODAY}.md"
    os.makedirs("digest", exist_ok=True)
    with open(md_path, "w", encoding="utf-8") as f:
        f.write(build_markdown(raw_results))
    print(f"  â†’ digest ì €ì¥: {md_path}")

    print(f"[ì™„ë£Œ] ìˆ˜ì§‘ëœ ì¿¼ë¦¬: {len(raw_results)}/{len(all_queries)}")


if __name__ == "__main__":
    main()
